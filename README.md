<<<<<<< HEAD
# 爬虫：从SCI-HUP下载文献
=======
# 爬虫：从SCI-HUP下载文献 
>>>>>>> 0352c0321520ac5ddf4ddb9ce36ab3aa9759ed46

## 阶段一：能够下载（提前准备好csv文件）

`目标：`

* 能够从SCI-HUB上下载文献

`实际完成：`

   * 能够从SCI-HUB上下载文献
* 目前只实现了使用DOI下载文献，其他方式（PMID，Title）等方式后续实现

`需要改进：`

   * 对于未成功下载的文献未进行错误处理，可能程序会抛出异常（如因为年限较远获取不到）
*  对于下载失败的文献写入失败文献信息（已完成：写入到了csv文件中）
*  第一次使用DOI来下载文献，如果DOI下载失败则尝试使用PMID,Title进行下载（待实现）
*  智能提取csv文献中的DOI,PMID,Title等相关信息（待实现）

### 阶段一总体实现

目前阶段一的代码可以使用程序正常下载文献，对于下载的文献会在终端实时输出日志，日志包括下载成功的文献，下载失败的文献，以及当前下载的第几篇文献，总共下载失败的文献数。并且，对于下载失败的文献会写入到csv文件中。

程序也统计了文献下载的成功率，以及下载文献总用时。




## 阶段二：下载自动化【待完成】（只需要数组关键词即可）

`目标：`
    * 1 完成阶段一的所有目标及改进
        * 2 能够只输入关键词从PUBMED,WEB_OF_SCIENCE网站上搜索相关文献，
          然后将爬取到的文献信息写入到csv文件中
        * 3 下载获取的csv文件中的文献


## 阶段三：自动智能化【待完成】（分类）

`目标：`

* 完成阶段二的所有目标及改进
* 能够依据以下关键字对文献进行分类：
  * 第一作者，期刊，影响因子等级...
  * 不同类别的文献放在一个文件夹

## 爬虫使用方法
### 阶段一使用方法
~~~txt
* 1 准备好csv文件
    ** 1.1 确保csv文件与当前爬虫文件在同一目录
    ** 1.2 csv文件至少包含四列，并且顺序必须为：
            PMID,Title，日期，DOI
* 2 设置要读取的文件名
    ** 2.1 在main(filename)模块中传入要读取的文件名
        ```python
            filename = "Capacitive.csv" # 我的文件名为'Capacitive.csv'
        ```
* 3 操作完直接执行即可

注：执行时需要确保自己的python安装了所需要的库（requests，bs4，pandas）
如果缺少对应的库，运行命令安装即可(例)：python -m pip install requests
~~~



<<<<<<< HEAD
**尾注**：由于最近时间比较紧，程序只能够满足基本的下载文献需求，刚好可用，后续有时间再慢慢完善~~~
=======
**尾注**：由于最近时间比较紧，程序只能够满足基本的下载文献需求，刚好可用，后续有时间再慢慢完善~~~
>>>>>>> 0352c0321520ac5ddf4ddb9ce36ab3aa9759ed46
